{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVUrlIRCQdH8"
   },
   "source": [
    "the retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6piQEH-Qlz2"
   },
   "source": [
    "etrieval models are often composed of two sub-models:\n",
    "\n",
    "1. A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n",
    "2. A candidate model computing the candidate representation (an equally-sized vector) using the candidate features\n",
    "The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKeJX4oZRn5O"
   },
   "source": [
    "cabdidate representation will be created from:\n",
    "1. movie title\n",
    "2. movie genre \n",
    "user representation will be created from:\n",
    "1. user age.\n",
    "2. user occupation.\n",
    "3. user gender.\n",
    "4. time as a contextual feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1VUezE8RFYl"
   },
   "source": [
    "# importing necessary libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W3r0WtXwRUrM"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.6 from \"d:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\python.exe\"\n  * The NumPy version is: \"1.19.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\lib\\site-packages\\numpy\\core\\multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[0;32m      8\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-45de5b88e8c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_recommenders\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \"\"\" % (sys.version_info[0], sys.version_info[1], sys.executable,\n\u001b[0;32m     47\u001b[0m         __version__, exc)\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.6 from \"d:\\Users\\R.Bakhtiari\\Anaconda3\\envs\\tensorforce\\python.exe\"\n  * The NumPy version is: \"1.19.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjwvLUo8Rsjh"
   },
   "source": [
    "# loading data from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_QJDnP7Rpjr"
   },
   "outputs": [],
   "source": [
    "#movies=tf.data.experimental.load('/content/drive/MyDrive/datasets/movielens_movies')\n",
    "ratings=tf.data.experimental.load('/content/drive/MyDrive/datasets/movielens_ratings')\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyVO6WvXSPcn"
   },
   "outputs": [],
   "source": [
    "\n",
    "user_data=ratings.map(lambda x:{\n",
    "    'id':x['user_id'],\n",
    "    'age':float(x['raw_user_age']),\n",
    "    'gender':float(x['user_gender']),\n",
    "    'occupation':x['user_occupation_text'],\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjPv84lvFF10",
    "outputId": "28f94de6-5dde-4a7c-9d4b-e6e5d5f5ab76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "  # Create 2 virtual GPUs with 1GB memory each\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n",
    "         tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRFnUm5xTiPG",
    "outputId": "db57090e-7f63-49ad-e2fe-d41570dc67a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 46.0, 'gender': 1.0, 'id': b'138', 'occupation': b'doctor'}\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in user_data.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)\n",
    "print('-------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY1ITuJkVAcQ"
   },
   "source": [
    "# creating a vocabulary for movie title and user occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEN08slcUSAM"
   },
   "outputs": [],
   "source": [
    "\n",
    "user_occupation=user_data.map(lambda x :x['occupation'])\n",
    "unique_user_occupation=np.unique(np.concatenate(list(user_occupation.batch(1_000))))\n",
    "\n",
    "\n",
    "\n",
    "user_id=movie_genres=user_data.map(lambda x :x['id'])\n",
    "unique_user_id=np.unique(np.concatenate(list(user_id.batch(1_000))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dRFS8OkXTIc"
   },
   "source": [
    "# spliting data to train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "debzTeMZWTXR"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "shuffled=user_data.shuffle(1_000,reshuffle_each_iteration=False)\n",
    "\n",
    "train=shuffled.take(80_000)\n",
    "test=shuffled.skip(80_000).take(10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97e4E0T8Xz3M"
   },
   "source": [
    "# building model\n",
    "Because we are building a two-tower retrieval model, we can build each tower separately and then combine them in the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUZjONjGYAmD"
   },
   "source": [
    "#  creating seprate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XlePon_aXr-Q"
   },
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "# age normalizer\n",
    "age_normalizer=tf.keras.layers.Normalization(\n",
    "    axis=None\n",
    ")\n",
    "ages=user_data.map(lambda x :x['age'])\n",
    "age_normalizer.adapt(ages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDWmFJ6azLJf"
   },
   "outputs": [],
   "source": [
    "embedding_dim=128\n",
    "# gender model\n",
    "# with strategy.scope():\n",
    "gender_model=tf.keras.Sequential(\n",
    "    [tf.keras.layers.IntegerLookup(vocabulary=[2])\n",
    "    ,tf.keras.layers.Embedding(3,2)\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# occupation model\n",
    "occupation_model=tf.keras.Sequential(\n",
    "    [tf.keras.layers.StringLookup(vocabulary=unique_user_occupation),\n",
    "    tf.keras.layers.Embedding(len(unique_user_occupation)+1,embedding_dim)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HTRN819jBga"
   },
   "source": [
    "# query tower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmV0NtNzjEpr"
   },
   "source": [
    "* user model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZyd-pNWi6iX"
   },
   "outputs": [],
   "source": [
    "# with strategy.scope():  \n",
    "class UserModel(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.age_normalizer=age_normalizer\n",
    "    self.gender_model=gender_model\n",
    "    self.occupation_model=occupation_model\n",
    "\n",
    "  @tf.function\n",
    "  def call(self,inputs):\n",
    "    out=tf.concat(\n",
    "        [tf.reshape(self.age_normalizer(inputs['age']),(-1,1)),\n",
    "        tf.cast(self.gender_model(tf.cast(inputs['gender'],dtype=tf.float32)),dtype=tf.float32),\n",
    "        self.occupation_model(inputs['occupation']),\n",
    "        ],axis=1\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76RtyoIHlWaQ"
   },
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "class QueryTower(tf.keras.Model):\n",
    "  def __init__(self,layers):\n",
    "    super().__init__()\n",
    "    self.user_model=UserModel()\n",
    "    self.dense_model=tf.keras.Sequential()\n",
    "    for layer in layers[:-1]:\n",
    "      self.dense_model.add(tf.keras.layers.Dense(layer,activation='relu'))\n",
    "    for layer in layers[-1:]:\n",
    "      self.dense_model.add(tf.keras.layers.Dense(layer))\n",
    "  @tf.function\n",
    "  def call(self,inputs):\n",
    "    v=self.user_model(inputs)\n",
    "    return self.dense_model(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6x7kDFNm2ao"
   },
   "source": [
    "# candidate tower\n",
    "* movie model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grSnVvRkm7Ho"
   },
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "# with strategy.scope():  \n",
    "class MovieModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.age_normalizer=age_normalizer\n",
    "      self.gender_model=gender_model\n",
    "      self.occupation_model=occupation_model\n",
    "\n",
    "    @tf.function\n",
    "    def call(self,inputs):\n",
    "\n",
    "      out=tf.concat(\n",
    "        [tf.reshape(self.age_normalizer(inputs['age']),(-1,1)),\n",
    "        tf.cast(self.gender_model(inputs['gender']),dtype=tf.float32),\n",
    "        self.occupation_model(inputs['occupation']),\n",
    "        ],axis=1\n",
    "    )\n",
    "      return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYj3r3jmoA1X"
   },
   "source": [
    "* candidate tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoYq0mqooF4v"
   },
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "class CandidateTower(tf.keras.Model):\n",
    "  def __init__(self,layers):\n",
    "    super().__init__()\n",
    "    self.user_model=UserModel()\n",
    "    self.dense_model=tf.keras.Sequential()\n",
    "    for layer in layers[:-1]:\n",
    "      self.dense_model.add(tf.keras.layers.Dense(layer,activation='relu'))\n",
    "    for layer in layers[-1:]:\n",
    "      self.dense_model.add(tf.keras.layers.Dense(layer))\n",
    "  @tf.function\n",
    "  def call(self,inputs):\n",
    "    v=self.user_model(inputs)\n",
    "    return self.dense_model(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zObnIak1cz54"
   },
   "source": [
    "# Metrics\n",
    "In our training data we have positive (user, user) pairs. To figure out how good our model is, we need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates: if the score for the positive pair is higher than for all other candidates, our model is highly accurate.\n",
    "\n",
    "To do this, we can use the tfrs.metrics.FactorizedTopK metric. The metric has one required argument: the dataset of candidates that are used as implicit negatives for evaluation.\n",
    "\n",
    "In our case, that's the movies dataset, converted into embeddings via our movie model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT8pD8HgenBU"
   },
   "source": [
    "# task\n",
    "The task itself is a Keras layer that takes the query and candidate embeddings as arguments, and returns the computed loss: we'll use that to implement the model's training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a186E6fre8Dz"
   },
   "source": [
    "# the full model\n",
    "We can now put it all together into a model. TFRS exposes a base model class (tfrs.models.Model) which streamlines building models: all we need to do is to set up the components in the __init__ method, and implement the compute_loss method, taking in the raw features and returning a loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MELVC-iVeuWv"
   },
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "class CombinedModels(tfrs.models.Model):\n",
    "  def __init__(self,layers):\n",
    "    super().__init__()\n",
    "    self.query_tower=QueryTower(layers)\n",
    "    self.candidate_tower=CandidateTower(layers)\n",
    "    self.task=tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=user_data.batch(128).map(self.candidate_tower)\n",
    "        )\n",
    "    )\n",
    "  @tf.function\n",
    "  def compute_loss(self, features,training=False):\n",
    "    # We only pass the user id and timestamp features into the query model. This\n",
    "    # is to ensure that the training inputs would have the same keys as the\n",
    "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "    # error when loading the query model after saving it.\n",
    "    query_embeddings=self.query_tower({\n",
    "        'age':features['age'],\n",
    "        'gender':features['gender'],\n",
    "        'occupation':features['occupation'],\n",
    "    })\n",
    "    candidate_embeddings=self.candidate_tower({\n",
    "        'age':features['age'],\n",
    "        'gender':features['gender'],\n",
    "        'occupation':features['occupation'],\n",
    "    })\n",
    "    return self.task(query_embeddings,candidate_embeddings,compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuVwSURFviHe"
   },
   "source": [
    "# preparing data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOf9oAUPvUW7"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjQXz4b_vvte"
   },
   "source": [
    "# training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAhzbfOJvxF_",
    "outputId": "be0e4d95-50c4-42f8-eaa2-b229ffb7ac1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 15s 19ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 15107.0096 - regularization_loss: 0.0000e+00 - total_loss: 15107.0096\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 9s 19ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 10697.8727 - regularization_loss: 0.0000e+00 - total_loss: 10697.8727\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 9s 18ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9395.0709 - regularization_loss: 0.0000e+00 - total_loss: 9395.0709\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 10s 18ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8893.6086 - regularization_loss: 0.0000e+00 - total_loss: 8893.6086\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 102s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 10831.1617 - regularization_loss: 0.0000e+00 - total_loss: 10831.1617 - val_factorized_top_k/top_1_categorical_accuracy: 0.0514 - val_factorized_top_k/top_5_categorical_accuracy: 0.0542 - val_factorized_top_k/top_10_categorical_accuracy: 0.0578 - val_factorized_top_k/top_50_categorical_accuracy: 0.0782 - val_factorized_top_k/top_100_categorical_accuracy: 0.0963 - val_loss: 8156.5088 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8156.5088\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "with strategy.scope():\n",
    "  model = CombinedModels([64,32,16])\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "one_layer_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "\n",
    "accuracy = one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print('========================================')\n",
    "#print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXlgiEzUJOdj"
   },
   "source": [
    "# making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgfD2lQqqryO"
   },
   "outputs": [],
   "source": [
    "d=[i for i in train.batch(1).take(20).cache()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z527200C7DcV",
    "outputId": "fd20b600-4691-4965-8a06-f713d81cf625"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7f2cd390fb90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k=1000\n",
    "index=tfrs.layers.factorized_top_k.BruteForce(model.query_tower,k=top_k)\n",
    "'''index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((candidate identifiers,\n",
    "                         candidate embeddings)))\n",
    ")'''\n",
    "index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((user_data.map(lambda x : x['id']).batch(100),\n",
    "                         user_data.batch(100).map(model.candidate_tower)))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zn05AHMXJqqE"
   },
   "source": [
    "# utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFh8z0tlJmNC"
   },
   "outputs": [],
   "source": [
    "def output_cleaner(outputs):\n",
    "  (unique, counts) = np.unique(outputs.numpy()[0], return_counts=True)\n",
    "  ziped_file=zip(unique,counts)\n",
    "  output_array=outputs.numpy()[0]\n",
    "  for uniques in unique:\n",
    "    to_be_deleted=np.where(output_array==uniques)[0]\n",
    "    output_array=np.delete(output_array,to_be_deleted[1:])\n",
    "  dictionary=dict(ziped_file)\n",
    "  ys =[]\n",
    "  \n",
    "  \n",
    "  for i,x in enumerate(output_array):\n",
    "    ys.append((f'{i+1}th person ', x))\n",
    "\n",
    "  return ys\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxhY2X5AJp1N"
   },
   "outputs": [],
   "source": [
    "def user_feature_extractor(wanted_id):\n",
    "  for j in user_data.batch(1):\n",
    "    i=0\n",
    "    if j['id'].numpy()[0]==wanted_id:\n",
    "      i+=1\n",
    "      if i==1:\n",
    "        print('user features: \\n')\n",
    "        print('age: ',j['age'].numpy()[0] )\n",
    "        print('gender ',j['gender'].numpy()[0])\n",
    "        print('occupation ',j['occupation'].numpy()[0])\n",
    "        print('id ',j['id'].numpy()[0],'\\n\\n')\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr5bK8E42bG_"
   },
   "outputs": [],
   "source": [
    "def input_data_creater_for_item_item(results,n):\n",
    "  input_data=[]\n",
    "  \n",
    "  for i in results[:n]:\n",
    "    wanted_id=i[1]\n",
    "    for j in user_data.batch(1):\n",
    "      i=0\n",
    "      if j['id'].numpy()[0]==wanted_id:\n",
    "        i+=1\n",
    "        if i==1:\n",
    "          input_data.append(j)\n",
    "          break\n",
    "  return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNXxt3X4YvlJ"
   },
   "outputs": [],
   "source": [
    "def n_first_recommended_users(results,n):\n",
    "  for i in results[:n]:\n",
    "    user_feature_extractor(i[1])\n",
    "    print('-------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVHU1i282bAF"
   },
   "outputs": [],
   "source": [
    "def n_last_recommended_users(results,n):\n",
    "  for i in results[-n:]:\n",
    "    user_feature_extractor(i[1])\n",
    "    print('-------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h56tQHv1JuRb"
   },
   "source": [
    "# print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-DaQmTfLviP"
   },
   "outputs": [],
   "source": [
    "print(f\"{top_k} users similar to user:{d[1]['id'].numpy()[0]} with below features \\n\\n\")\n",
    "user_feature_extractor(d[1]['id'].numpy()[0])\n",
    "_,recommes=index(d[1])\n",
    "recommended_users=output_cleaner(recommes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcinHsqQ3n-P"
   },
   "outputs": [],
   "source": [
    "n_first_recommended_users(recommended_users,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "wJTIQryR4kVE",
    "outputId": "c73520e9-c9b9-4661-fa8d-3101c7209b55"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/content/user_to_user_.py\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    user_data=ratings.map(lambda x:{\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import user_to_user_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UarzHpyV_kQx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "user to user .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
