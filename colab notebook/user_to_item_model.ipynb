{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVUrlIRCQdH8"
      },
      "source": [
        "the retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6piQEH-Qlz2"
      },
      "source": [
        "etrieval models are often composed of two sub-models:\n",
        "\n",
        "1. A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n",
        "2. A candidate model computing the candidate representation (an equally-sized vector) using the candidate features\n",
        "The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKeJX4oZRn5O"
      },
      "source": [
        "cabdidate representation will be created from:\n",
        "1. movie title\n",
        "2. movie genre \n",
        "user representation will be created from:\n",
        "1. user age.\n",
        "2. user occupation.\n",
        "3. user gender.\n",
        "4. time as a contextual feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1VUezE8RFYl"
      },
      "source": [
        "# importing necessary libreries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aep6MsLQCLK",
        "outputId": "3baedfeb-bd2e-4cf9-c9bb-dda199529ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 40.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 13.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W3r0WtXwRUrM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import numpy as np\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjwvLUo8Rsjh"
      },
      "source": [
        "# loading data from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_QJDnP7Rpjr",
        "outputId": "27215cfc-38a1-4fda-ca93-7bf83a4ec53f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bucketized_user_age': 45.0,\n",
            " 'movie_genres': array([7]),\n",
            " 'movie_id': b'357',\n",
            " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
            " 'raw_user_age': 46.0,\n",
            " 'timestamp': 879024327,\n",
            " 'user_gender': True,\n",
            " 'user_id': b'138',\n",
            " 'user_occupation_label': 4,\n",
            " 'user_occupation_text': b'doctor',\n",
            " 'user_rating': 4.0,\n",
            " 'user_zip_code': b'53211'}\n"
          ]
        }
      ],
      "source": [
        "movies=tf.data.experimental.load('/content/drive/MyDrive/datasets/movielens_movies')\n",
        "ratings=tf.data.experimental.load('/content/drive/MyDrive/datasets/movielens_ratings')\n",
        "for x in ratings.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gP8Wn1QTWNi",
        "outputId": "7da720aa-648a-4a1e-f7e7-ee67728c9f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'movie_genres': array([4]),\n",
            " 'movie_id': b'1681',\n",
            " 'movie_title': b'You So Crazy (1994)'}\n"
          ]
        }
      ],
      "source": [
        "for x in movies.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "VyVO6WvXSPcn"
      },
      "outputs": [],
      "source": [
        "data=ratings.map(lambda x:{\n",
        "    'age':x['raw_user_age'],\n",
        "    'user_id':x['user_id'],\n",
        "    'movie_id':x['movie_id'],\n",
        "    'time':x['timestamp'],\n",
        "    'gender':x['user_gender'],\n",
        "    'occupation':x['user_occupation_text'],\n",
        "    'movie_title':x['movie_title'],\n",
        "    'genre':x['movie_genres'][0]\n",
        "})\n",
        "user_data=ratings.map(lambda x:{\n",
        "    'age':x['raw_user_age'],\n",
        "    'user_id':x['user_id'],\n",
        "    'movie_id':x['movie_id'],\n",
        "    'time':x['timestamp'],\n",
        "    'gender':x['user_gender'],\n",
        "    'occupation':x['user_occupation_text'],\n",
        "    'movie_title':x['movie_title'],\n",
        "    'genre':x['movie_genres'][0]\n",
        "})\n",
        "movie_data=movies.map(lambda x: {'movie_title':x['movie_title'],\n",
        "                      'genre':x['movie_genres'][0]S})\n",
        "movie_title=movies.map(lambda x:x['movie_title']\n",
        "                     )\n",
        "movie_id=movies.map(lambda x:x['movie_id']\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRFnUm5xTiPG",
        "outputId": "dffb0e1b-0f24-4f0f-86f2-01be656b67fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'age': 46.0,\n",
            " 'gender': 1.0,\n",
            " 'genre': 7.0,\n",
            " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
            " 'occupation': b'doctor',\n",
            " 'time': 879024300.0}\n",
            "-------------------------------\n",
            "{'genre': 4.0, 'movie_title': b'You So Crazy (1994)'}\n"
          ]
        }
      ],
      "source": [
        "for x in user_data.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)\n",
        "print('-------------------------------')\n",
        "for x in movie_data.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY1ITuJkVAcQ"
      },
      "source": [
        "# creating a vocabulary for movie title and user occupation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "uEN08slcUSAM"
      },
      "outputs": [],
      "source": [
        "movie_titles=user_data.map(lambda x:x['movie_title'])\n",
        "unique_movie_titles=np.unique(np.concatenate(list(movie_titles.batch(1_000))))\n",
        "user_occupation=user_data.map(lambda x :x['occupation'])\n",
        "unique_user_occupation=np.unique(np.concatenate(list(user_occupation.batch(1_000))))\n",
        "movie_genres=user_data.map(lambda x :x['genre'])\n",
        "unique_movie_genres=np.unique(np.concatenate(list(movie_genres.batch(1_000))))\n",
        "user_gender=movie_genres=user_data.map(lambda x :x['gender'])\n",
        "unique_user_gender=np.unique(np.concatenate(list(user_gender.batch(1_000))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYCaJmQyWC79"
      },
      "source": [
        "# creating a normalizer for time feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "N_5BToz2V9GF"
      },
      "outputs": [],
      "source": [
        "timestamp=user_data.map(lambda x : x['time'])\n",
        "min_timestamp=np.unique(np.concatenate(list(timestamp.batch(1_000)))).min()\n",
        "max_timestamp=np.unique(np.concatenate(list(timestamp.batch(1_000)))).max()\n",
        "time_bucket=np.linspace(min_timestamp,max_timestamp,1000)\n",
        "ages=user_data.map(lambda x : x['age'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dRFS8OkXTIc"
      },
      "source": [
        "# spliting data to train and test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "debzTeMZWTXR"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(123)\n",
        "shuffled=user_data.shuffle(1_000,reshuffle_each_iteration=False)\n",
        "\n",
        "train=shuffled.take(80_000)\n",
        "test=shuffled.skip(80_000).take(10_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97e4E0T8Xz3M"
      },
      "source": [
        "# building model\n",
        "Because we are building a two-tower retrieval model, we can build each tower separately and then combine them in the final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUZjONjGYAmD"
      },
      "source": [
        "#  creating seprate models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "XlePon_aXr-Q"
      },
      "outputs": [],
      "source": [
        "embedding_dim=128\n",
        "# age normalizer\n",
        "age_normalizer=tf.keras.layers.Normalization(\n",
        "    axis=None\n",
        ")\n",
        "\n",
        "# gender model\n",
        "gender_model=tf.keras.Sequential(\n",
        "    [tf.keras.layers.IntegerLookup(vocabulary=unique_user_gender),\n",
        "     tf.keras.layers.Embedding(len(unique_user_gender)+1,2)\n",
        "    ]\n",
        ")\n",
        "# genre model\n",
        "genre_model=tf.keras.Sequential([tf.keras.layers.IntegerLookup(vocabulary=unique_movie_genres),\n",
        "    tf.keras.layers.Embedding(len(unique_movie_genres)+1,embedding_dim)\n",
        "     \n",
        "    ]\n",
        ")\n",
        "\n",
        "# movie model\n",
        "movie_model=tf.keras.Sequential(\n",
        "    [tf.keras.layers.StringLookup(vocabulary=unique_movie_titles),\n",
        "     tf.keras.layers.Embedding(len(unique_movie_titles)+1,embedding_dim)\n",
        "    ]\n",
        ")\n",
        "# occupation model\n",
        "occupation_model=tf.keras.Sequential(\n",
        "    [tf.keras.layers.StringLookup(vocabulary=unique_user_occupation),\n",
        "     tf.keras.layers.Embedding(len(unique_user_occupation)+1,embedding_dim)\n",
        "    ]\n",
        ")\n",
        "# time normalizer\n",
        "time_model=tf.keras.Sequential(\n",
        "    [tf.keras.layers.Discretization(time_bucket.tolist()),\n",
        "     tf.keras.layers.Embedding(len(time_bucket)+1,embedding_dim-4)\n",
        "    ]\n",
        ")\n",
        "time_nirmalizer=tf.keras.layers.Normalization(axis=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_nirmalizer.adapt(timestamp)\n",
        "age_normalizer.adapt(ages)"
      ],
      "metadata": {
        "id": "2WKcMSVfSyBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HTRN819jBga"
      },
      "source": [
        "# query tower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmV0NtNzjEpr"
      },
      "source": [
        "* user model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "BZyd-pNWi6iX"
      },
      "outputs": [],
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.age_normalizer=age_normalizer\n",
        "    self.gender_model=gender_model\n",
        "    self.occupation_model=occupation_model\n",
        "    self.time_model=time_model\n",
        "    self.time_normalizer=time_nirmalizer\n",
        "\n",
        "  def call(self,inputs):\n",
        "    out=tf.concat(\n",
        "        [tf.reshape(self.age_normalizer(inputs['age']),(-1,1)),\n",
        "         self.gender_model(inputs['gender']),\n",
        "         self.occupation_model(inputs['occupation']),\n",
        "         self.time_model(inputs['time']),\n",
        "         tf.reshape(self.time_normalizer(inputs['time']),(-1,1))\n",
        "        ],axis=1\n",
        "    )\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "76RtyoIHlWaQ"
      },
      "outputs": [],
      "source": [
        "class QueryTower(tf.keras.Model):\n",
        "  def __init__(self,layers):\n",
        "    super().__init__()\n",
        "    self.user_model=UserModel()\n",
        "    self.dense_model=tf.keras.Sequential()\n",
        "    for layer in layers[:-1]:\n",
        "      self.dense_model.add(tf.keras.layers.Dense(layer,activation='relu'))\n",
        "    for layer in layers[-1:]:\n",
        "      self.dense_model.add(tf.keras.layers.Dense(layer))\n",
        "  def call(self,inputs):\n",
        "    v=self.user_model(inputs)\n",
        "    return self.dense_model(v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6x7kDFNm2ao"
      },
      "source": [
        "# candidate tower\n",
        "* movie model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "grSnVvRkm7Ho"
      },
      "outputs": [],
      "source": [
        "class MovieModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.movie_model=movie_model\n",
        "    self.genre_model=genre_model\n",
        "    self.genre_normalizer=genre_model\n",
        "  def call(self,inputs):\n",
        "    out=tf.concat(\n",
        "        [self.movie_model(inputs['movie_title']),\n",
        "         self.genre_model(inputs['genre']),\n",
        "\n",
        "        ],axis=1\n",
        "    )\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYj3r3jmoA1X"
      },
      "source": [
        "* candidate tower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "IoYq0mqooF4v"
      },
      "outputs": [],
      "source": [
        "class CandidateTower(tf.keras.Model):\n",
        "  def __init__(self,layers):\n",
        "    super().__init__()\n",
        "    self.movie_model=MovieModel()\n",
        "    self.dense=tf.keras.Sequential()\n",
        "    for layer in layers[:-1]:\n",
        "      self.dense.add(tf.keras.layers.Dense(layer,activation='relu'))\n",
        "    for layer in layers[-1:]:\n",
        "      self.dense.add(tf.keras.layers.Dense(layer))\n",
        "  def call(self,inputs):\n",
        "    x=self.movie_model(inputs)\n",
        "    return self.dense(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zObnIak1cz54"
      },
      "source": [
        "# Metrics\n",
        "In our training data we have positive (user, movie) pairs. To figure out how good our model is, we need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates: if the score for the positive pair is higher than for all other candidates, our model is highly accurate.\n",
        "\n",
        "To do this, we can use the tfrs.metrics.FactorizedTopK metric. The metric has one required argument: the dataset of candidates that are used as implicit negatives for evaluation.\n",
        "\n",
        "In our case, that's the movies dataset, converted into embeddings via our movie model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT8pD8HgenBU"
      },
      "source": [
        "# task\n",
        "The task itself is a Keras layer that takes the query and candidate embeddings as arguments, and returns the computed loss: we'll use that to implement the model's training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a186E6fre8Dz"
      },
      "source": [
        "# the full model\n",
        "We can now put it all together into a model. TFRS exposes a base model class (tfrs.models.Model) which streamlines building models: all we need to do is to set up the components in the __init__ method, and implement the compute_loss method, taking in the raw features and returning a loss value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "MELVC-iVeuWv"
      },
      "outputs": [],
      "source": [
        "class CombinedModels(tfrs.models.Model):\n",
        "  def __init__(self,layers):\n",
        "    super().__init__()\n",
        "    self.query_tower=QueryTower(layers)\n",
        "    self.candidate_tower=CandidateTower(layers)\n",
        "    self.task=tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=movie_data.batch(128).map(self.candidate_tower)\n",
        "        )\n",
        "    )\n",
        "  def compute_loss(self, features,training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings=self.query_tower({\n",
        "        'age':features['age'],\n",
        "        'gender':features['gender'],\n",
        "        'occupation':features['occupation'],\n",
        "        'time':features['time']\n",
        "    })\n",
        "    candidate_embeddings=self.candidate_tower({\n",
        "        'movie_title':features['movie_title'],\n",
        "        'genre':features['genre']\n",
        "    })\n",
        "    return self.task(query_embeddings,candidate_embeddings,compute_metrics=not training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuVwSURFviHe"
      },
      "source": [
        "# preparing data to train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nOf9oAUPvUW7"
      },
      "outputs": [],
      "source": [
        "cached_train = train.shuffle(100_000).batch(2048)\n",
        "cached_test = test.batch(4096).cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjQXz4b_vvte"
      },
      "source": [
        "# training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAhzbfOJvxF_",
        "outputId": "ebfa1873-21c2-4f11-ea33-a7c79079c14b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "40/40 [==============================] - 10s 88ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 15698.5623 - regularization_loss: 0.0000e+00 - total_loss: 15698.5623\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 10s 110ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14846.1274 - regularization_loss: 0.0000e+00 - total_loss: 14846.1274\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 9s 88ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14755.0695 - regularization_loss: 0.0000e+00 - total_loss: 14755.0695\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 9s 87ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14673.7022 - regularization_loss: 0.0000e+00 - total_loss: 14673.7022\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 33s 556ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14584.1660 - regularization_loss: 0.0000e+00 - total_loss: 14584.1660 - val_factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0038 - val_factorized_top_k/top_10_categorical_accuracy: 0.0084 - val_factorized_top_k/top_50_categorical_accuracy: 0.0489 - val_factorized_top_k/top_100_categorical_accuracy: 0.0977 - val_loss: 13267.9814 - val_regularization_loss: 0.0000e+00 - val_total_loss: 13267.9814\n",
            "Top-100 accuracy: 0.10.\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "model = CombinedModels([64,32,16])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "one_layer_history = model.fit(\n",
        "    cached_train,\n",
        "    validation_data=cached_test,\n",
        "    validation_freq=5,\n",
        "    epochs=num_epochs,\n",
        "    verbose=1)\n",
        "\n",
        "accuracy = one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
        "print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d=[i for i in data.batch(1).take(20).cache()]\n",
        "index=tfrs.layers.factorized_top_k.BruteForce(model.query_tower,k=20)\n",
        "'''index.index_from_dataset(\n",
        "    tf.data.Dataset.zip((candidate identifiers,\n",
        "                         candidate embeddings)))\n",
        ")'''\n",
        "index.index_from_dataset(\n",
        "    tf.data.Dataset.zip((movie_title.batch(100),\n",
        "                         movie_data.batch(100).map(model.candidate_tower)))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LKQxrezUHw5",
        "outputId": "d0f933af-6d91-4ff7-f828-b18571e71016"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7f14f0e2b590>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utility functions"
      ],
      "metadata": {
        "id": "Zn05AHMXJqqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output_cleaner(outputs):\n",
        "  (unique, counts) = np.unique(outputs.numpy()[0], return_counts=True)\n",
        "  ziped_file=zip(unique,counts)\n",
        "  output_array=outputs.numpy()[0]\n",
        "  for uniques in unique:\n",
        "    to_be_deleted=np.where(output_array==uniques)[0]\n",
        "    output_array=np.delete(output_array,to_be_deleted[1:])\n",
        "  dictionary=dict(ziped_file)\n",
        "  ys =[]\n",
        "  \n",
        "  \n",
        "  for i,x in enumerate(output_array):\n",
        "    ys.append((f'{i+1}th movie ', x))\n",
        "\n",
        "\n",
        "  return ys\n",
        "      \n"
      ],
      "metadata": {
        "id": "vFh8z0tlJmNC"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def movie_feature_extractor(id_wanted):\n",
        "  for j in movie_data.batch(1):\n",
        "    i=0\n",
        "    if j['id'].numpy()[0]==id_wanted:\n",
        "      i+=1\n",
        "      if i==1:\n",
        "        print('movie features: \\n')\n",
        "        print('title: ',j['title'].numpy()[0] )\n",
        "        print('genre ',j['genre'].numpy()[0])\n",
        "        print('id ',j['id'].numpy()[0],'\\n\\n')\n",
        "        break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fxhY2X5AJp1N"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_first_recommended_movies(results,n):\n",
        "  for i in out[:n]:\n",
        "    movie_feature_extractor(i[1])\n",
        "    print('-------------------------')\n"
      ],
      "metadata": {
        "id": "xjJcQwrZ2k4e"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_last_recommended_movies(results,n):\n",
        "  for i in out[-n:]:\n",
        "    movie_feature_extractor(i[1])\n",
        "    print('-------------------------')\n"
      ],
      "metadata": {
        "id": "--qlEMDYYv_Q"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXlgiEzUJOdj"
      },
      "source": [
        "# making prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_,recommes=index(d[0])\n"
      ],
      "metadata": {
        "id": "0iSFd-sxUuHp"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_creator_for_ranker_from_UTI(results,n):\n",
        "  input_data=[]\n",
        "  for i in results[0][:n]:\n",
        "    wanted_id=i.numpy()\n",
        "    for j in data.batch(1):\n",
        "      i=0\n",
        "\n",
        "      if j['movie_id'].numpy()[0]==wanted_id:\n",
        "        i+=1\n",
        "        if i==1:\n",
        "          input_data.append(j)\n",
        "          break\n",
        "  return input_data\n"
      ],
      "metadata": {
        "id": "FhkoZAI6cZlo"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dV5qSrscdWCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Zn05AHMXJqqE"
      ],
      "name": "user to item model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}