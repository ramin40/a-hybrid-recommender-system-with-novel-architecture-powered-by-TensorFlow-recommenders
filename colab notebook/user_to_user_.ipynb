{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "user to user .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVUrlIRCQdH8"
      },
      "source": [
        "the retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6piQEH-Qlz2"
      },
      "source": [
        "etrieval models are often composed of two sub-models:\n",
        "\n",
        "1. A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n",
        "2. A candidate model computing the candidate representation (an equally-sized vector) using the candidate features\n",
        "The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKeJX4oZRn5O"
      },
      "source": [
        "cabdidate representation will be created from:\n",
        "1. movie title\n",
        "2. movie genre \n",
        "user representation will be created from:\n",
        "1. user age.\n",
        "2. user occupation.\n",
        "3. user gender.\n",
        "4. time as a contextual feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1VUezE8RFYl"
      },
      "source": [
        "# importing necessary libreries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aep6MsLQCLK",
        "outputId": "14999f29-3e81-4ef5-eb09-05c99cc23845"
      },
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 32.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3r0WtXwRUrM"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import numpy as np\n",
        "import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjwvLUo8Rsjh"
      },
      "source": [
        "# loading data from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_QJDnP7Rpjr"
      },
      "source": [
        "#movies=tf.data.experimental.load('/content/drive/MyDrive/datasets/movielens_movies')\n",
        "ratings=tf.data.experimental.load('/content/drive/MyDrive/datasets/movielens_ratings')\n",
        "for x in ratings.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyVO6WvXSPcn"
      },
      "source": [
        "\n",
        "user_data=ratings.map(lambda x:{\n",
        "    'id':x['user_id'],\n",
        "    'age':x['raw_user_age'],\n",
        "    'gender':x['user_gender'],\n",
        "    'occupation':x['user_occupation_text'],\n",
        "\n",
        "})\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if gpus:\n",
        "  # Create 2 virtual GPUs with 1GB memory each\n",
        "  try:\n",
        "    tf.config.set_logical_device_configuration(\n",
        "        gpus[0],\n",
        "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n",
        "         tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
        "    logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
        "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Virtual devices must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjPv84lvFF10",
        "outputId": "28f94de6-5dde-4a7c-9d4b-e6e5d5f5ab76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Virtual devices cannot be modified after being initialized\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRFnUm5xTiPG",
        "outputId": "db57090e-7f63-49ad-e2fe-d41570dc67a6"
      },
      "source": [
        "for x in user_data.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)\n",
        "print('-------------------------------')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'age': 46.0, 'gender': 1.0, 'id': b'138', 'occupation': b'doctor'}\n",
            "-------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY1ITuJkVAcQ"
      },
      "source": [
        "# creating a vocabulary for movie title and user occupation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEN08slcUSAM"
      },
      "source": [
        "\n",
        "user_occupation=user_data.map(lambda x :x['occupation'])\n",
        "unique_user_occupation=np.unique(np.concatenate(list(user_occupation.batch(1_000))))\n",
        "\n",
        "\n",
        "\n",
        "user_id=movie_genres=user_data.map(lambda x :x['id'])\n",
        "unique_user_id=np.unique(np.concatenate(list(user_id.batch(1_000))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dRFS8OkXTIc"
      },
      "source": [
        "# spliting data to train and test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "debzTeMZWTXR"
      },
      "source": [
        "tf.random.set_seed(123)\n",
        "shuffled=user_data.shuffle(1_000,reshuffle_each_iteration=False)\n",
        "\n",
        "train=shuffled.take(80_000)\n",
        "test=shuffled.skip(80_000).take(10_000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97e4E0T8Xz3M"
      },
      "source": [
        "# building model\n",
        "Because we are building a two-tower retrieval model, we can build each tower separately and then combine them in the final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUZjONjGYAmD"
      },
      "source": [
        "#  creating seprate models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlePon_aXr-Q"
      },
      "source": [
        "# with strategy.scope():\n",
        "# age normalizer\n",
        "age_normalizer=tf.keras.layers.Normalization(\n",
        "    axis=None\n",
        ")\n",
        "ages=user_data.map(lambda x :x['age'])\n",
        "age_normalizer.adapt(ages)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=128\n",
        "# gender model\n",
        "# with strategy.scope():\n",
        "gender_model=tf.keras.Sequential(\n",
        "    [tf.keras.layers.IntegerLookup(vocabulary=[2])\n",
        "    ,tf.keras.layers.Embedding(3,2)\n",
        "\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# occupation model\n",
        "occupation_model=tf.keras.Sequential(\n",
        "    [tf.keras.layers.StringLookup(vocabulary=unique_user_occupation),\n",
        "    tf.keras.layers.Embedding(len(unique_user_occupation)+1,embedding_dim)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZDWmFJ6azLJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HTRN819jBga"
      },
      "source": [
        "# query tower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmV0NtNzjEpr"
      },
      "source": [
        "* user model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZyd-pNWi6iX"
      },
      "source": [
        "# with strategy.scope():  \n",
        "class UserModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.age_normalizer=age_normalizer\n",
        "    self.gender_model=gender_model\n",
        "    self.occupation_model=occupation_model\n",
        "\n",
        "  @tf.function\n",
        "  def call(self,inputs):\n",
        "    out=tf.concat(\n",
        "        [tf.reshape(self.age_normalizer(inputs['age']),(-1,1)),\n",
        "        tf.cast(self.gender_model(tf.cast(inputs['gender'],dtype=tf.float32)),dtype=tf.float32),\n",
        "        self.occupation_model(inputs['occupation']),\n",
        "        ],axis=1\n",
        "    )\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76RtyoIHlWaQ"
      },
      "source": [
        "# with strategy.scope():\n",
        "class QueryTower(tf.keras.Model):\n",
        "  def __init__(self,layers):\n",
        "    super().__init__()\n",
        "    self.user_model=UserModel()\n",
        "    self.dense_model=tf.keras.Sequential()\n",
        "    for layer in layers[:-1]:\n",
        "      self.dense_model.add(tf.keras.layers.Dense(layer,activation='relu'))\n",
        "    for layer in layers[-1:]:\n",
        "      self.dense_model.add(tf.keras.layers.Dense(layer))\n",
        "  @tf.function\n",
        "  def call(self,inputs):\n",
        "    v=self.user_model(inputs)\n",
        "    return self.dense_model(v)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6x7kDFNm2ao"
      },
      "source": [
        "# candidate tower\n",
        "* movie model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grSnVvRkm7Ho"
      },
      "source": [
        "from typing import cast\n",
        "# with strategy.scope():  \n",
        "class MovieModel(tf.keras.Model):\n",
        "  \n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.age_normalizer=age_normalizer\n",
        "      self.gender_model=gender_model\n",
        "      self.occupation_model=occupation_model\n",
        "\n",
        "    @tf.function\n",
        "    def call(self,inputs):\n",
        "\n",
        "      out=tf.concat(\n",
        "        [tf.reshape(self.age_normalizer(inputs['age']),(-1,1)),\n",
        "        tf.cast(self.gender_model(inputs['gender']),dtype=tf.float32),\n",
        "        self.occupation_model(inputs['occupation']),\n",
        "        ],axis=1\n",
        "    )\n",
        "      return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYj3r3jmoA1X"
      },
      "source": [
        "* candidate tower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoYq0mqooF4v"
      },
      "source": [
        "# with strategy.scope():\n",
        "class CandidateTower(tf.keras.Model):\n",
        "  def __init__(self,layers):\n",
        "    super().__init__()\n",
        "    self.user_model=UserModel()\n",
        "    self.dense_model=tf.keras.Sequential()\n",
        "    for layer in layers[:-1]:\n",
        "      self.dense_model.add(tf.keras.layers.Dense(layer,activation='relu'))\n",
        "    for layer in layers[-1:]:\n",
        "      self.dense_model.add(tf.keras.layers.Dense(layer))\n",
        "  @tf.function\n",
        "  def call(self,inputs):\n",
        "    v=self.user_model(inputs)\n",
        "    return self.dense_model(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zObnIak1cz54"
      },
      "source": [
        "# Metrics\n",
        "In our training data we have positive (user, user) pairs. To figure out how good our model is, we need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates: if the score for the positive pair is higher than for all other candidates, our model is highly accurate.\n",
        "\n",
        "To do this, we can use the tfrs.metrics.FactorizedTopK metric. The metric has one required argument: the dataset of candidates that are used as implicit negatives for evaluation.\n",
        "\n",
        "In our case, that's the movies dataset, converted into embeddings via our movie model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT8pD8HgenBU"
      },
      "source": [
        "# task\n",
        "The task itself is a Keras layer that takes the query and candidate embeddings as arguments, and returns the computed loss: we'll use that to implement the model's training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a186E6fre8Dz"
      },
      "source": [
        "# the full model\n",
        "We can now put it all together into a model. TFRS exposes a base model class (tfrs.models.Model) which streamlines building models: all we need to do is to set up the components in the __init__ method, and implement the compute_loss method, taking in the raw features and returning a loss value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MELVC-iVeuWv"
      },
      "source": [
        "# with strategy.scope():\n",
        "class CombinedModels(tfrs.models.Model):\n",
        "  def __init__(self,layers):\n",
        "    super().__init__()\n",
        "    self.query_tower=QueryTower(layers)\n",
        "    self.candidate_tower=CandidateTower(layers)\n",
        "    self.task=tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=user_data.batch(128).map(self.candidate_tower)\n",
        "        )\n",
        "    )\n",
        "  @tf.function\n",
        "  def compute_loss(self, features,training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings=self.query_tower({\n",
        "        'age':features['age'],\n",
        "        'gender':features['gender'],\n",
        "        'occupation':features['occupation'],\n",
        "    })\n",
        "    candidate_embeddings=self.candidate_tower({\n",
        "        'age':features['age'],\n",
        "        'gender':features['gender'],\n",
        "        'occupation':features['occupation'],\n",
        "    })\n",
        "    return self.task(query_embeddings,candidate_embeddings,compute_metrics=not training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuVwSURFviHe"
      },
      "source": [
        "# preparing data to train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOf9oAUPvUW7"
      },
      "source": [
        "cached_train = train.shuffle(100_000).batch(2048)\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjQXz4b_vvte"
      },
      "source": [
        "# training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAhzbfOJvxF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0e4d95-50c4-42f8-eaa2-b229ffb7ac1e"
      },
      "source": [
        "num_epochs = 5\n",
        "# with strategy.scope():\n",
        "model = CombinedModels([64,32,16])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "one_layer_history = model.fit(\n",
        "    cached_train,\n",
        "    validation_data=cached_test,\n",
        "    validation_freq=5,\n",
        "    epochs=num_epochs,\n",
        "    verbose=1)\n",
        "\n",
        "accuracy = one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
        "print('========================================')\n",
        "#print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Epoch 1/5\n",
            "40/40 [==============================] - 15s 19ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 15107.0096 - regularization_loss: 0.0000e+00 - total_loss: 15107.0096\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 9s 19ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 10697.8727 - regularization_loss: 0.0000e+00 - total_loss: 10697.8727\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 9s 18ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9395.0709 - regularization_loss: 0.0000e+00 - total_loss: 9395.0709\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 10s 18ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 8893.6086 - regularization_loss: 0.0000e+00 - total_loss: 8893.6086\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 102s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 10831.1617 - regularization_loss: 0.0000e+00 - total_loss: 10831.1617 - val_factorized_top_k/top_1_categorical_accuracy: 0.0514 - val_factorized_top_k/top_5_categorical_accuracy: 0.0542 - val_factorized_top_k/top_10_categorical_accuracy: 0.0578 - val_factorized_top_k/top_50_categorical_accuracy: 0.0782 - val_factorized_top_k/top_100_categorical_accuracy: 0.0963 - val_loss: 8156.5088 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8156.5088\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXlgiEzUJOdj"
      },
      "source": [
        "# making prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d=[i for i in train.batch(1).take(20).cache()]\n"
      ],
      "metadata": {
        "id": "LgfD2lQqqryO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z527200C7DcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd20b600-4691-4965-8a06-f713d81cf625"
      },
      "source": [
        "top_k=1000\n",
        "index=tfrs.layers.factorized_top_k.BruteForce(model.query_tower,k=top_k)\n",
        "'''index.index_from_dataset(\n",
        "    tf.data.Dataset.zip((candidate identifiers,\n",
        "                         candidate embeddings)))\n",
        ")'''\n",
        "index.index_from_dataset(\n",
        "    tf.data.Dataset.zip((user_data.map(lambda x : x['id']).batch(100),\n",
        "                         user_data.batch(100).map(model.candidate_tower)))\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7f2cd390fb90>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utility functions"
      ],
      "metadata": {
        "id": "Zn05AHMXJqqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output_cleaner(outputs):\n",
        "  (unique, counts) = np.unique(outputs.numpy()[0], return_counts=True)\n",
        "  ziped_file=zip(unique,counts)\n",
        "  output_array=outputs.numpy()[0]\n",
        "  for uniques in unique:\n",
        "    to_be_deleted=np.where(output_array==uniques)[0]\n",
        "    output_array=np.delete(output_array,to_be_deleted[1:])\n",
        "  dictionary=dict(ziped_file)\n",
        "  ys =[]\n",
        "  \n",
        "  \n",
        "  for i,x in enumerate(output_array):\n",
        "    ys.append((f'{i+1}th person ', x))\n",
        "\n",
        "  return ys\n",
        "      \n"
      ],
      "metadata": {
        "id": "vFh8z0tlJmNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_feature_extractor(wanted_id):\n",
        "  for j in user_data.batch(1):\n",
        "    i=0\n",
        "    if j['id'].numpy()[0]==wanted_id:\n",
        "      i+=1\n",
        "      if i==1:\n",
        "        print('user features: \\n')\n",
        "        print('age: ',j['age'].numpy()[0] )\n",
        "        print('gender ',j['gender'].numpy()[0])\n",
        "        print('occupation ',j['occupation'].numpy()[0])\n",
        "        print('id ',j['id'].numpy()[0],'\\n\\n')\n",
        "        break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fxhY2X5AJp1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_data_creater_for_item_item(results,n):\n",
        "  input_data=[]\n",
        "  \n",
        "  for i in results[:n]:\n",
        "    wanted_id=i[1]\n",
        "    for j in user_data.batch(1):\n",
        "      i=0\n",
        "      if j['id'].numpy()[0]==wanted_id:\n",
        "        i+=1\n",
        "        if i==1:\n",
        "          input_data.append(j)\n",
        "          break\n",
        "  return input_data\n"
      ],
      "metadata": {
        "id": "yr5bK8E42bG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_first_recommended_users(results,n):\n",
        "  for i in results[:n]:\n",
        "    user_feature_extractor(i[1])\n",
        "    print('-------------------------')\n"
      ],
      "metadata": {
        "id": "QNXxt3X4YvlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_last_recommended_users(results,n):\n",
        "  for i in results[-n:]:\n",
        "    user_feature_extractor(i[1])\n",
        "    print('-------------------------')\n"
      ],
      "metadata": {
        "id": "UVHU1i282bAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# print predictions"
      ],
      "metadata": {
        "id": "h56tQHv1JuRb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-DaQmTfLviP"
      },
      "source": [
        "print(f\"{top_k} users similar to user:{d[1]['id'].numpy()[0]} with below features \\n\\n\")\n",
        "user_feature_extractor(d[1]['id'].numpy()[0])\n",
        "_,recommes=index(d[1])\n",
        "recommended_users=output_cleaner(recommes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_first_recommended_users(recommended_users,10)"
      ],
      "metadata": {
        "id": "AcinHsqQ3n-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UarzHpyV_kQx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}